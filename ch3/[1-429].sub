{18}{142} 好，欢迎来到今天的课堂
{144}{197}今天我们讲数据的整理（Data Wrangling）
{208}{306}这个英文名可能听上去有点怪
{307}{373}但它解决的基本问题就是
{374}{488}把一种格式的数据转换成另一种
{495}{553}那这个任务再平常不过了
{554}{616}我说的不仅是图片格式之间的转换
{617}{717}还有可能是你现有的文本文件、日志文件
{718}{803}你想得到它们的其他格式
{804}{896}比如图表或者统计数据
{902}{990}那么我认为的数据处理
{991}{1078}就是像这样把一个数据
{1079}{1148}以另一种方式表达
{1149}{1301}我们在前面几节课已经见过几个例子了
{1310}{1397}例如当你使用管道操作符的时候
{1398}{1522}它会把一个程序的输出喂给另一个程序
{1523}{1604}其实此时，你就在进行某种形式的数据处理
{1617}{1688}那么我们这节课的主要内容就是
{1689}{1778}看看有什么神秘的数据处理魔法
{1779}{1865}以及数据处理的高效方法
{1931}{1990}要处理数据
{1991}{2023}首先你得有数据来源
{2024}{2099}要有能加以实践的数据
{2135}{2236}那优质的数据来源就多了去了
{2239}{2313}那么我们今天的讲义的练习里
{2314}{2353}就会给你许多的样例数据
{2354}{2465}而今天的课呢，我打算用系统日志
{2466}{2580}我在荷兰那地儿跑着个服务器
{2581}{2640}呃，这在当时来说十分合理[*]
{2646}{2753}在那个服务器上呢，跑着一个
{2754}{2836}`systemd` 自带的记录日志的后台进程
{2837}{2930}这是一个挺标准的 Linux 日志机制
{2942}{3014}然后我们可以通过 Linux 的一个
{3015}{3121}`journalctl` 命令来看系统日志
{3129}{3181}那么我要做的事
{3182}{3246}就是对这个日志做一些转换
{3247}{3322}然后看看里面有没有啥有趣的东西
{3345}{3414}你可以看到我跑完这个命令以后
{3415}{3500}获得了这么多的数据
{3503}{3644}因为这个日志文件，它里面有超多东西
{3645}{3704}我的服务器上发生了不少事情
{3705}{3785}你看这一条是一月一日的
{3786}{3898}后面还有更久远的很多东西
{3899}{3991}那我们要做的第一件事就是缩小日志量
{3992}{4054}我们只看一部分的内容
{4055}{4124}此时 `grep` 就是你的最佳伙伴了
{4125}{4240}我们用管道把 `ssh` 的输出接到 `grep` 上
{4247}{4331}我们还没仔细聊过 `ssh`|
{4332}{4438}但它是一种通过命令行，远程访问计算机的方式
{4439}{4562}当你把服务器放到公网上之后
{4563}{4664}世界各地的人都想连接然后登录进去
{4665}{4706}然后控制你的服务器
{4709}{4793}那我就想看看他们是咋整的 [*]
{4799}{4872}那我就 `grep SSH`
{4873}{5056}然后你就能够~~很快的~~看到这会输出很多东西
{5070}{5165}理论上来说是这样的但是实际上很慢...
{5174}{5203}好
{5204}{5275}你可以看到它生成了
{5277}{5335}这么这么这么多的内容
{5336}{5433}这样很难看出发生了什么
{5439}{5527}所以我们只来看看这些人
{5528}{5587}用了什么用户名来尝试登录
{5588}{5767}你可以看到这里有几行写着「无效用户，断开连接」 [*]
{5768}{5804}然后后面是用户名
{5813}{5852}现在我只想要这种日志条目
{5853}{5894}我只关注这些东西
{5900}{5988}那我现在再来点修改
{5989}{6166}我在最后加上个 `Disconnected from`（断开连接）
{6183}{6298}你想想底部的这条命令流水线是如何运作的
{6299}{6415}首先它会通过网络，把整个日志传到这个电脑里
{6416}{6531}然后在本地跑 `grep` 找出所有含 `ssh` 的行
{6532}{6591}然后再在本地更进一步的去筛选
{6592}{6643}这是不是有点浪费 [*]
{6644}{6703}因为我根本不关心其他的条目
{6704}{6766}远程服务器上也有个 Shell
{6767}{6937}那我就把整个命令搬到服务器上运行
{6938}{7028}那么现在，你，SSH
{7029}{7102}你给我在服务器上整这三个活
{7103}{7187}然后拿回来的数据我再接到 `less` 上面
{7223}{7261}那这会发生什么呢
{7262}{7326}其实是一样的数据筛选
{7327}{7375}只是把工作搬到服务器上了
{7376}{7497}而服务器只会回传我想要的行
{7519}{7621}然后我在本地把数据用管道接到了 `less` 上
{7622}{7669}`less` 是个分页显示程序
{7670}{7729}你会看到一些例子…
{7730}{7799}其实当你键入 `man`
{7801}{7835}然后后面接某些命令
{7836}{7879}你实际上已经见过这个程序了
{7880}{7981}使用分页程序可以方便的把长长的内容
{7982}{8041}适配到终端的大小
{8052}{8134}然后让你上下滚动来浏览
{8135}{8214}而不是在你的屏幕上一滚而过
{8215}{8307}执行这个命令的时候还是要花一些时间
{8308}{8374}因为服务器要解析一堆日志文件
{8375}{8483}特别是 `grep` 会先缓存输出 [*]
{8490}{8597}所以它还卡在这
{8600}{8696}让我看看不这样的话会不会好一点[*]
{8987}{9082}为啥不听我的话...
{9111}{9175}好吧让我搞点小手段
{9176}{9295}你假装没看见
{9549}{9608}也有可能是这个网络差得离谱
{9609}{9643}可能是这两个原因之一
{9644}{9703}还好我有备而来
{9704}{9852}上课前我执行了这个命令
{9878}{10009}它会把前面的这串命令的输出
{10010}{10069}放到我电脑里的这个文件里
{10070}{10129}我在办公室里跑了一次
{10141}{10245}而前面这串命令所做的事就是
{10246}{10305}把所有包含 `disconnect from` 的 
{10306}{10370}SSH 日志下载到本地
{10374}{10415}这真是个好东西
{10416}{10501}因为我没有必要每次都传输整个日志
{10508}{10598}我只想要以它开头的行
{10620}{10696}那我们现在来看看 `ssh.log`
{10700}{10758}你可以看到它有这么这么多
{10759}{10856}写着「与无效的用户断开连接」
{10857}{10916}或者「已认证的用户」，等等
{10941}{11005}我们要做的就是在这些日志上整活
{11006}{11044}这也意味着
{11045}{11143}在这之后我们并不需要再走 SSH 的流程
{11144}{11193}我们可以直接 `cat` 这个文件
{11196}{11247}然后在它上面进行操作
{11283}{11353}此外让我来展示一下这个分页器
{11354}{11457}如果我 `cat ssh.log` 
{11458}{11495}然后把管道接到 `less` 上
{11496}{11529}它就会给我一个分页器
{11530}{11567}我就可以上下滚动了
{11568}{11617}把字体调小一点点？
{11664}{11741}这样我可以滚动浏览这个文件了
{11742}{11794}那么我还可以用些
{11795}{11848}类似 Vim 的按键操作来浏览
{11849}{11936}`Ctrl+u` 向上翻，`Ctrl+d` 向下翻
{11937}{11979}以及按 `q` 退出
{12037}{12120}这仍然有很多内容
{12121}{12226}里面还是有很多我不感兴趣的垃圾信息
{12227}{12313}我只想看看这些用户名是些啥
{12314}{12398}那么我们就要来用
{12400}{12447}一个叫做 `sed` 的工具了
{12458}{12570}流编辑器 `sed` 是一个更早期的|
{12571}{12661}一个叫做 `ed` 的东西的改版
{12662}{12782}这东西非常之怪，你们肯定不想用
{12788}{12825}诶你有啥问题
{12826}{12877}_抱歉我可能漏听了_
{12878}{12922}_但是 `tsp` 是个啥 [*]_
{12923}{13033}哦 `tsp` 是我的远程计算机的名字
{13115}{13177}所以 `sed` 是一个“流”编辑器
{13178}{13350}可以让你修改流（stream）中的内容
{13364}{13450}你可以认为这个命令大概是做文本替换
{13452}{13512}但实际上 `sed` 是一个在输入流上操作的
{13513}{13585}完整的编程语言 [*]
{13586}{13667}那么 `sed` 的一个最常用操作就是
{13668}{13792}在输入流之上执行替换表达式
{13793}{13859}那么这东西长什么样呢
{13860}{13903}让我写给你看看
{13972}{14036}好 现在我要把管道接到 `sed` 上
{14037}{14103}然后我告诉它我想把
{14104}{14182}所有 `Disconnected from` 前面的东西
{14183}{14242}全部丢掉
{14313}{14374}这可能有些奇怪
{14375}{14419}但是你会观察到
{14420}{14577}这些 SSH 里的日期、域名、进程 ID
{14578}{14649}我并不关心，干脆统统把它删掉
{14650}{14821}`Disconnected from` 这几个字每条日志都有
{14822}{14869}也可以删掉
{14870}{14953}那我就要写一个 `sed` 表达式
{14958}{15028}而此处我写的是一个 `s/` 表达式
{15030}{15089}也就是替换表达式（**s**ubstitute）
{15090}{15241}这个表达式接受两个以斜线分隔的参数
{15252}{15328}第一个参数是要找的字符串
{15333}{15406}而第二个是要换成的字符串
{15423}{15510}这里的意思就是，按这个字符串模式搜索
{15511}{15570}然后把它换成空的
{15578}{15641}最后我把它接到 `less` 上
{15657}{15780}看到了吗？它把这些行的开头剪掉了
{15820}{15888}用起来真的爽
{15889}{15932}但是你可能会疑惑
{15933}{16012}我在这写的这玩意是个啥
{16028}{16120}那个 `.*` 是干啥的
{16127}{16205}这实际上是正则表达式的一个例子
{16212}{16348}正则表达式，你之前写程序可能见过
{16358}{16422}但是你一旦用起命令行
{16424}{16465}你会发现这东西用得特别多
{16466}{16525}特别是对于像这样的数据处理
{16541}{16685}正则表达式是一个很有力的文本匹配方式
{16695}{16757}你不一定要把它用在文本上
{16758}{16808}但匹配文本是最普遍的用途
{16817}{16862}在正则表达式里
{16863}{16998}你可以活用一套特殊字符
{16999}{17090}这些字符不会直接匹配它们本身
{17091}{17236}而是匹配某一类的字符或者字符串
{17243}{17320}本质上来说它生成了一段程序
{17321}{17366}来在文本中进行查找
{17367}{17477}例如 `.` 代表「匹配一个任意字符」
{17522}{17621}而如果在某一字符后面加上 `*`
{17622}{17708}那它代表匹配零次或多次该字符
{17744}{17798}那么这个 pattern（模式）所描述的就是
{17799}{17878}任意的、零个或多个字符 [*]
{17888}{17978}然后跟着一个字符串 `Disconnected from`
{18000}{18051}这里就是说，我找到这样的字符串
{18052}{18098}然后把它们换成空的
{18118}{18239}正则表达式有一大把像这样的特殊字符
{18240}{18274}各有各的含义
{18275}{18303}你可以好好运用
{18304}{18338}我们已经讲过了 `*`
{18339}{18371}它匹配零或多个字符
{18377}{18406}还有一个 `+`
{18407}{18455}作用是匹配一次或多次左面的模式 [*]
{18456}{18485}那么这样的意思就是
{18486}{18549}我想要前面那个 pattern 匹配至少一次
{18595}{18655}此外还有方括号
{18659}{18785}可以让你匹配多种字符中的一种
{18786}{18869}好 我现在搞个字符串
{18870}{18929}比如说 `aba`
{18937}{19105}我想把 `a` 和 `b` 换成空的
{19187}{19282}那么我就让 pattern 去把
{19283}{19366}要么是 `a` 要么是 `b` 的字符
{19367}{19426}换成空的
{19463}{19516}就算我把第一个字符换成了 `b`
{19517}{19562}还是会输出 `ba`
{19577}{19602}那你可能就会想了
{19603}{19645}为啥它只替换一次呢
{19646}{19712}这是因为正则表达式
{19713}{19764}在默认模式下
{19765}{19906}每行只匹配一次、替换一次
{19907}{19966}这是 sed **默认**模式下做的事
{19974}{20042}你可以再加个 `g` 修饰符
{20043}{20126}意思是只要能，就尽量多匹配
{20152}{20215}然后整行就没了
{20216}{20291}因为每个字符都是 `a` 或 `b` 之一
{20305}{20348}如果我再加个 `c`
{20349}{20407}它就移除 `c` 之外的所有东西
{20408}{20506}如果再向字符串内加其它字符
{20507}{20537}也都会保留下来
{20538}{20610}但是 `a` 和 `b` 都会被去掉
{20727}{20902}你还可以给他加点修饰符
{21089}{21185}跑这个命令会发生什么呢
{21186}{21260}它的意思是我想要把零个或多个
{21263}{21330}`ab` 这个字符串
{21345}{21393}换成空的
{21409}{21505}单独的一个 `a` 不会被替换掉 
{21516}{21577}单独一个 `b` 也不会被替换掉
{21583}{21632}但是 `ab` 连一起
{21633}{21682}它就会被替换掉了
{21872}{21914}`sed` 你好蠢啊
{21957}{22084}这里加上 `-E` 是因为 `sed` 真的很老了
{22089}{22205}它只支持很旧版本的正则表达式
{22206}{22288}一般你要加上 `-E` 开关跑
{22289}{22351}这样他就会用一套支持更多东西的
{22352}{22383}更现代的语法
{22412}{22471}如果它没法使用 `-E` 开关
{22472}{22546}那你就得在括号前面加 `\`
{22547}{22644}来告诉它使用“特殊含义”的括号
{22653}{22723}不然它就只会匹配括号本身
{22724}{22772}那可能不是你想要的
{22798}{22917}注意它把这里的 `ab` 替换掉了
{22923}{22981}把这里的 `ab` 也替换掉了
{22982}{23027}但是把这个 `c` 
{23028}{23083}还有末尾的 `a` 留下来了
{23084}{23170}因为它和 pattern 不匹配
{23206}{23284}你可以把 pattern 的任意部分括成一组
{23285}{23362}也有「选择」之类的东西
{23363}{23426}例如你可以让它移除
{23427}{23518}任意匹配 `ab` 或 `bc` 的字符串
{23600}{23674}然后你会注意到这个 `ab` 没了
{23687}{23753}但就算这个 `bc` 和 pattern 相匹配
{23757}{23807}它并没有被删除
{23808}{23881}这是因为 `ab` 已经被删除了
{23901}{23960}这个 `ab` 被删掉了，对吧
{23964}{23993}`c` 还留着
{23994}{24045}这里的 `ab` 被删去了
{24054}{24139}因为这个 `c` 依然不匹配，还留着
{24148}{24232}如果我把这个 `a` 删掉
{24233}{24302}这个 `ab` 的 pattern
{24303}{24348}就不会匹配到这个 `b`
{24349}{24377}然后它就会被留下来
{24378}{24428}然后 `bc` 就会匹配到这个 `bc` 
{24429}{24466}随后就会被删掉
{24488}{24570}你刚开始接触的时候
{24571}{24614}正则用起来会很麻烦
{24615}{24670}就算当你熟练之后
{24671}{24718}这东西看起来也很吓人 [*]
{24731}{24781}这也是为什么
{24782}{24877}人们常常会使用正则调试器的原因
{24878}{24920}过一会儿我们会看到
{24926}{24988}但首先让我们编写一个 pattern
{24989}{25141}能够匹配日志条目…呃…匹配我们在处理的条目
{25157}{25280}让我们先从文件里拿几行出来
{25281}{25325}那就前五行吧
{25332}{25408}看，这几行现在是这样一个形式
{25454}{25612}但是我们要做的是，只留用户名
{25632}{25872}那么我们就会想把它写成这样...
{26075}{26144}等下 让我先给你看一个东西
{26145}{26204}我们先整出来
{26205}{26542}写着 _这样一串_ 的一行
{26556}{26632}那么这是一条登录记录
{26646}{26775}有人打算以 `Disconnected from` 作为用户名登录
{26802}{26841}_（学生）少了个 `s`_
{26842}{26991}少了个 `s` 吗？emmmm...
{26992}{27015}_（学生）第一个 `Disconnected`_
{27016}{27075}**`Disconnected`** 多谢
{27122}{27221}那么你会发现这个命令连用户名一起移除了
{27222}{27297}这是因为像 `.*`
{27301}{27377}这种匹配一个**范围**的表达式
{27383}{27425}它们是用贪心策略
{27426}{27496}去尽可能多的匹配
{27497}{27633}因此虽然我们在这里想保留用户名
{27644}{27794}但是这个 pattern 会一路匹配到它第二次
{27795}{27835}也就是最后一次出现
{27836}{27900}所以包括用户名在内
{27901}{27960}在这之前出现的文本都会被删掉
{27966}{28003}那么我们就要想一个
{28004}{28053}机智一点的方法来匹配
{28054}{28109}而不仅仅是使用 `.*`
{28119}{28193}这样如果输入比较诡异
{28194}{28253}可能会输出一些诡异的东西
{28279}{28385}好 让我们来看看怎么匹配这些行
{28394}{28466}首先先跑个 `head` （过滤一下）
{28674}{28756}嗯...让我们从头开始构造这个 pattern
{28801}{28881}显然我们不想 `\` 满地跑
{28882}{28990}因此首先我们整个 `-E`
{29004}{29069}这些行是这样一个形式
{29070}{29129}先是 `from`
{29130}{29203}有些写了 `invalid`
{29231}{29348}有些又没有 是吧
{29357}{29431}那这里的问号就是匹配 0 或 1 次
{29442}{29491}那这样写就是说
{29492}{29565}0 或 1 个 invalid 后面跟个空格\
{29581}{29630}然后是 `user`……？
{29711}{29786}啊——多了个空格 可不敢乱多
{29809}{29892}然后后面有个用户名
{29910}{30008}然后后面是...
{30009}{30093}然后后面是个 IP 地址
{30100}{30188}这里可以用区间匹配的那些语法
{30189}{30269}这个的意思就是 匹配 `0` 到 `9` 或者 `.` 
{30287}{30355}这是 IP 地址的特征
{30371}{30424}而且我们要匹配多次
{30472}{30538}然后后面是 `port`（端口）
{30539}{30598}所以我们匹配一个固定的字符串 `port`
{30599}{30754}然后再来一次数字 `0` 到 `9`，匹配多次
{30827}{30904}除此之外我们还要做一件事
{30905}{30950}我们要给表达式打锚点
{30951}{31034}正则表达式里有两个特殊字符
{31035}{31150}`^` 匹配行开头
{31161}{31227}而 `$` 匹配行结尾
{31255}{31293}那我们这样写
{31294}{31391}就代表着这个正则表达式匹配了一整行
{31420}{31458}为什么要这样写呢
{31459}{31532}假设有个人把它的用户名
{31533}{31596}设成了这一整条日志文本
{31624}{31676}那当你匹配的时候
{31677}{31777}就会匹配到用户名
{31788}{31824}坏耶——
{31842}{31920}一般来说锚点能加尽量加
{31921}{31980}避免这种偶然事件发生
{31992}{32059}现在看看跑这个命令有什么效果
{32064}{32111}这个命令删掉了好多行
{32114}{32146}但还是留下来了一些
{32151}{32249}例如这个 最后有个 `[preauth]`
{32268}{32343}那我们把它炖了吧
{32349}{32486}空格，`preauth`，方括号
{32487}{32545}方括号是特殊字符要转义
{32561}{32577}好耶
{32583}{32669}再多来几行呢
{32691}{32750}啊 还是有奇怪的东西
{32751}{32792}这些行非空
{32793}{32852}那就意味着 pattern 和它不匹配
{32885}{32924}拿这个来说
{32925}{33023}它写的是 `authenticating` 而不是 `invalid`
{33032}{33061}好吧
{33093}{33164}改成 `invalid` 或者 `authenticating` 之一
{33165}{33216}在用户名之前匹配零次或一次
{33248}{33272}现在如何
{33312}{33365}看上去挺稳的
{33386}{33466}但是这个输出没多少用啊
{33467}{33533}它只是成功地
{33534}{33593}把日志的每一行都清空了
{33594}{33642}这不太有用啊
