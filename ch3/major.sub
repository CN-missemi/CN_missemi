{18}{142} 好，欢迎来到今天的课堂
{144}{197}今天我们讲数据的整理（Data Wrangling）
{208}{306}这个英文名可能听上去有点怪
{307}{373}但它解决的基本问题就是
{374}{488}把一种格式的数据转换成另一种
{495}{553}那这个任务再平常不过了
{554}{616}我说的不仅是图片格式之间的转换
{617}{717}还有可能是你现有的文本文件、日志文件
{718}{803}你想得到它们的其他格式
{804}{896}比如图表或者统计数据
{902}{990}那么我认为的数据处理
{991}{1078}就是像这样把一个数据
{1079}{1148}以另一种方式表达
{1149}{1301}我们在前面几节课已经见过几个例子了
{1310}{1397}例如当你使用管道操作符的时候
{1398}{1522}它会把一个程序的输出喂给另一个程序
{1523}{1604}其实此时，你就在进行某种形式的数据处理
{1617}{1688}那么我们这节课的主要内容就是
{1689}{1778}看看有什么神秘的数据处理魔法
{1779}{1865}以及数据处理的高效方法
{1931}{1990}要处理数据
{1991}{2023}首先你得有数据来源
{2024}{2099}要有能加以实践的数据
{2135}{2236}那优质的数据来源就多了去了
{2239}{2313}那么我们今天的讲义的练习里
{2314}{2353}就会给你许多的样例数据
{2354}{2465}而今天的课呢，我打算用系统日志
{2466}{2580}我在荷兰那地儿跑着个服务器
{2581}{2640}呃，这在当时来说十分合理[*]
{2646}{2753}在那个服务器上呢，跑着一个
{2754}{2836}`systemd` 自带的记录日志的后台进程
{2837}{2930}这是一个挺标准的 Linux 日志机制
{2942}{3014}然后我们可以通过 Linux 的一个
{3015}{3121}`journalctl` 命令来看系统日志
{3129}{3181}那么我要做的事
{3182}{3246}就是对这个日志做一些转换
{3247}{3322}然后看看里面有没有啥有趣的东西
{3345}{3414}你可以看到我跑完这个命令以后
{3415}{3500}获得了这么多的数据
{3503}{3644}因为这个日志文件，它里面有超多东西
{3645}{3704}我的服务器上发生了不少事情
{3705}{3785}你看这一条是一月一日的
{3786}{3898}后面还有更久远的很多东西
{3899}{3991}那我们要做的第一件事就是缩小日志量
{3992}{4054}我们只看一部分的内容
{4055}{4124}此时 `grep` 就是你的最佳伙伴了
{4125}{4240}我们用管道把 `ssh` 的输出接到 `grep` 上
{4247}{4331}我们还没仔细聊过 `ssh`|
{4332}{4438}但它是一种通过命令行，远程访问计算机的方式
{4439}{4562}当你把服务器放到公网上之后
{4563}{4664}世界各地的人都想连接然后登录进去
{4665}{4706}然后控制你的服务器
{4709}{4793}那我就想看看他们是咋整的 [*]
{4799}{4872}那我就 `grep SSH`
{4873}{5056}然后你就能够~~很快的~~看到这会输出很多东西
{5070}{5165}理论上来说是这样的但是实际上很慢...
{5174}{5203}好
{5204}{5275}你可以看到它生成了
{5277}{5335}这么这么这么多的内容
{5336}{5433}这样很难看出发生了什么
{5439}{5527}所以我们只来看看这些人
{5528}{5587}用了什么用户名来尝试登录
{5588}{5767}你可以看到这里有几行写着「无效用户，断开连接」 [*]
{5768}{5804}然后后面是用户名
{5813}{5852}现在我只想要这种日志条目
{5853}{5894}我只关注这些东西
{5900}{5988}那我现在再来点修改
{5989}{6166}我在最后加上个 `Disconnected from`（断开连接）
{6183}{6298}你想想底部的这条命令流水线是如何运作的
{6299}{6415}首先它会通过网络，把整个日志传到这个电脑里
{6416}{6531}然后在本地跑 `grep` 找出所有含 `ssh` 的行
{6532}{6591}然后再在本地更进一步的去筛选
{6592}{6643}这是不是有点浪费 [*]
{6644}{6703}因为我根本不关心其他的条目
{6704}{6766}远程服务器上也有个 Shell
{6767}{6937}那我就把整个命令搬到服务器上运行
{6938}{7028}那么现在，你，SSH
{7029}{7102}你给我在服务器上整这三个活
{7103}{7187}然后拿回来的数据我再接到 `less` 上面
{7223}{7261}那这会发生什么呢
{7262}{7326}其实是一样的数据筛选
{7327}{7375}只是把工作搬到服务器上了
{7376}{7497}而服务器只会回传我想要的行
{7519}{7621}然后我在本地把数据用管道接到了 `less` 上
{7622}{7669}`less` 是个分页显示程序
{7670}{7729}你会看到一些例子…
{7730}{7799}其实当你键入 `man`
{7801}{7835}然后后面接某些命令
{7836}{7879}你实际上已经见过这个程序了
{7880}{7981}使用分页程序可以方便的把长长的内容
{7982}{8041}适配到终端的大小
{8052}{8134}然后让你上下滚动来浏览
{8135}{8214}而不是在你的屏幕上一滚而过
{8215}{8307}执行这个命令的时候还是要花一些时间
{8308}{8374}因为服务器要解析一堆日志文件
{8375}{8483}特别是 `grep` 会先缓存输出 [*]
{8490}{8597}所以它还卡在这
{8600}{8696}让我看看不这样的话会不会好一点 [*]
{8987}{9082}为啥不听我的话...
{9111}{9175}好吧让我搞点小手段
{9176}{9295}你假装没看见
{9549}{9608}也有可能是这个网络差得离谱
{9609}{9643}可能是这两个原因之一
{9644}{9703}还好我有备而来
{9704}{9852}上课前我执行了这个命令
{9878}{10009}它会把前面的这串命令的输出
{10010}{10069}放到我电脑里的这个文件里
{10070}{10129}我在办公室里跑了一次
{10141}{10245}而前面这串命令所做的事就是
{10246}{10305}把所有包含 `disconnect from` 的 
{10306}{10370}SSH 日志下载到本地
{10374}{10415}这真是个好东西
{10416}{10501}因为我没有必要每次都传输整个日志
{10508}{10598}我只想要以它开头的行
{10620}{10696}那我们现在来看看 `ssh.log`
{10700}{10758}你可以看到它有这么这么多
{10759}{10856}写着「与无效的用户断开连接」
{10857}{10916}或者「已认证的用户」，等等
{10941}{11005}我们要做的就是在这些日志上整活
{11006}{11044}这也意味着
{11045}{11143}在这之后我们并不需要再走 SSH 的流程
{11144}{11193}我们可以直接 `cat` 这个文件
{11196}{11247}然后在它上面进行操作
{11283}{11353}此外让我来展示一下这个分页器
{11354}{11457}如果我 `cat ssh.log` 
{11458}{11495}然后把管道接到 `less` 上
{11496}{11529}它就会给我一个分页器
{11530}{11567}我就可以上下滚动了
{11568}{11617}把字体调小一点点？
{11664}{11741}这样我可以滚动浏览这个文件了
{11742}{11794}那么我还可以用些
{11795}{11848}类似 Vim 的按键操作来浏览
{11849}{11936}`Ctrl+u` 向上翻，`Ctrl+d` 向下翻
{11937}{11979}以及按 `q` 退出
{12037}{12120}这仍然有很多内容
{12121}{12226}里面还是有很多我不感兴趣的垃圾信息
{12227}{12313}我只想看看这些用户名是些啥
{12314}{12398}那么我们就要来用
{12400}{12447}一个叫做 `sed` 的工具了
{12458}{12570}流编辑器 `sed` 是一个更早期的|
{12571}{12661}一个叫做 `ed` 的东西的改版
{12662}{12782}这东西非常之怪，你们肯定不想用
{12788}{12825}诶你有啥问题
{12826}{12877}_抱歉我可能漏听了_
{12878}{12922}_但是 `tsp` 是个啥 [*]_
{12923}{13033}哦 `tsp` 是我的远程计算机的名字
{13115}{13177}所以 `sed` 是一个“流”编辑器
{13178}{13350}可以让你修改流（stream）中的内容
{13364}{13450}你可以认为这个命令大概是做文本替换
{13452}{13512}但实际上 `sed` 是一个在输入流上操作的
{13513}{13585}完整的编程语言 [*]
{13586}{13667}那么 `sed` 的一个最常用操作就是
{13668}{13792}在输入流之上执行替换表达式
{13793}{13859}那么这东西长什么样呢
{13860}{13903}让我写给你看看
{13972}{14036}好 现在我要把管道接到 `sed` 上
{14037}{14103}然后我告诉它我想把
{14104}{14182}所有 `Disconnected from` 前面的东西
{14183}{14242}全部丢掉
{14313}{14374}这可能有些奇怪
{14375}{14419}但是你会观察到
{14420}{14577}这些 SSH 里的日期、域名、进程 ID
{14578}{14649}我并不关心，干脆统统把它删掉
{14650}{14821}`Disconnected from` 这几个字每条日志都有
{14822}{14869}也可以删掉
{14870}{14953}那我就要写一个 `sed` 表达式
{14958}{15028}而此处我写的是一个 `s/` 表达式
{15030}{15089}也就是替换表达式（**s**ubstitute）
{15090}{15241}这个表达式接受两个以斜线分隔的参数
{15252}{15328}第一个参数是要找的字符串
{15333}{15406}而第二个是要换成的字符串
{15423}{15510}这里的意思就是，按这个字符串模式搜索
{15511}{15570}然后把它换成空的
{15578}{15641}最后我把它接到 `less` 上
{15657}{15780}看到了吗？它把这些行的开头剪掉了
{15820}{15888}用起来真的爽
{15889}{15932}但是你可能会疑惑
{15933}{16012}我在这写的这玩意是个啥
{16028}{16120}那个 `.*` 是干啥的
{16127}{16205}这实际上是正则表达式的一个例子
{16212}{16348}正则表达式，你之前写程序可能见过
{16358}{16422}但是你一旦用起命令行
{16424}{16465}你会发现这东西用得特别多
{16466}{16525}特别是对于像这样的数据处理
{16541}{16685}正则表达式是一个很有力的文本匹配方式
{16695}{16757}你不一定要把它用在文本上
{16758}{16808}但匹配文本是最普遍的用途
{16817}{16862}在正则表达式里
{16863}{16998}你可以活用一套特殊字符
{16999}{17090}这些字符不会直接匹配它们本身
{17091}{17236}而是匹配某一类的字符或者字符串
{17243}{17320}本质上来说它生成了一段程序
{17321}{17366}来在文本中进行查找
{17367}{17477}例如 `.` 代表「匹配一个任意字符」
{17522}{17621}而如果在某一字符后面加上 `*`
{17622}{17708}那它代表匹配零次或多次该字符
{17744}{17798}那么这个 pattern（模式）所描述的就是
{17799}{17878}任意的、零个或多个字符 [*]
{17888}{17978}然后跟着一个字符串 `Disconnected from`
{18000}{18051}这里就是说，我找到这样的字符串
{18052}{18098}然后把它们换成空的
{18118}{18239}正则表达式有一大把像这样的特殊字符
{18240}{18274}各有各的含义
{18275}{18303}你可以好好运用
{18304}{18338}我们已经讲过了 `*`
{18339}{18371}它匹配零或多个字符
{18377}{18406}还有一个 `+`
{18407}{18455}作用是匹配一次或多次左面的模式 [*]
{18456}{18485}那么这样的意思就是
{18486}{18549}我想要前面那个 pattern 匹配至少一次
{18595}{18655}此外还有方括号
{18659}{18785}可以让你匹配多种字符中的一种
{18786}{18869}好 我现在搞个字符串
{18870}{18929}比如说 `aba`
{18937}{19105}我想把 `a` 和 `b` 换成空的
{19187}{19282}那么我就让 pattern 去把
{19283}{19366}要么是 `a` 要么是 `b` 的字符
{19367}{19426}换成空的
{19463}{19516}就算我把第一个字符换成了 `b`
{19517}{19562}还是会输出 `ba`
{19577}{19602}那你可能就会想了
{19603}{19645}为啥它只替换一次呢
{19646}{19712}这是因为正则表达式
{19713}{19764}在默认模式下
{19765}{19906}每行只匹配一次、替换一次
{19907}{19966}这是 sed **默认**模式下做的事
{19974}{20042}你可以再加个 `g` 修饰符
{20043}{20126}意思是只要能，就尽量多匹配
{20152}{20215}然后整行就没了
{20216}{20291}因为每个字符都是 `a` 或 `b` 之一
{20305}{20348}如果我再加个 `c`
{20349}{20407}它就移除 `c` 之外的所有东西
{20408}{20506}如果再向字符串内加其它字符
{20507}{20537}也都会保留下来
{20538}{20610}但是 `a` 和 `b` 都会被去掉
{20727}{20902}你还可以给他加点修饰符
{21089}{21185}跑这个命令会发生什么呢
{21186}{21260}它的意思是我想要把零个或多个
{21263}{21330}`ab` 这个字符串
{21345}{21393}换成空的
{21409}{21505}单独的一个 `a` 不会被替换掉 
{21516}{21577}单独一个 `b` 也不会被替换掉
{21583}{21632}但是 `ab` 连一起
{21633}{21682}它就会被替换掉了
{21872}{21914}`sed` 你好蠢啊
{21957}{22084}这里加上 `-E` 是因为 `sed` 真的很老了
{22089}{22205}它只支持很旧版本的正则表达式
{22206}{22288}一般你要加上 `-E` 开关跑
{22289}{22351}这样他就会用一套支持更多东西的
{22352}{22383}更现代的语法
{22412}{22471}如果它没法使用 `-E` 开关
{22472}{22546}那你就得在括号前面加 `\`
{22547}{22644}来告诉它使用“特殊含义”的括号
{22653}{22723}不然它就只会匹配括号本身
{22724}{22772}那可能不是你想要的
{22798}{22917}注意它把这里的 `ab` 替换掉了
{22923}{22981}把这里的 `ab` 也替换掉了
{22982}{23027}但是把这个 `c` 
{23028}{23083}还有末尾的 `a` 留下来了
{23084}{23170}因为它和 pattern 不匹配
{23206}{23284}你可以把 pattern 的任意部分括成一组
{23285}{23362}也有「选择」之类的东西
{23363}{23426}例如你可以让它移除
{23427}{23518}任意匹配 `ab` 或 `bc` 的字符串
{23600}{23674}然后你会注意到这个 `ab` 没了
{23687}{23753}但就算这个 `bc` 和 pattern 相匹配
{23757}{23807}它并没有被删除
{23808}{23881}这是因为 `ab` 已经被删除了
{23901}{23960}这个 `ab` 被删掉了，对吧
{23964}{23993}`c` 还留着
{23994}{24045}这里的 `ab` 被删去了
{24054}{24139}因为这个 `c` 依然不匹配，还留着
{24148}{24232}如果我把这个 `a` 删掉
{24233}{24302}这个 `ab` 的 pattern
{24303}{24348}就不会匹配到这个 `b`
{24349}{24377}然后它就会被留下来
{24378}{24428}然后 `bc` 就会匹配到这个 `bc` 
{24429}{24466}随后就会被删掉
{24488}{24570}你刚开始接触的时候
{24571}{24614}正则用起来会很麻烦
{24615}{24670}就算当你熟练之后
{24671}{24718}这东西看起来也很吓人 [*]
{24731}{24781}这也是为什么
{24782}{24877}人们常常会使用正则调试器的原因
{24878}{24920}过一会儿我们会看到
{24926}{24988}但首先让我们编写一个 pattern
{24989}{25141}能够匹配日志条目…呃…匹配我们在处理的条目
{25157}{25280}让我们先从文件里拿几行出来
{25281}{25325}那就前五行吧
{25332}{25408}看，这几行现在是这样一个形式
{25454}{25612}但是我们要做的是，只留用户名
{25632}{25872}那么我们就会想把它写成这样...
{26075}{26144}等下 让我先给你看一个东西
{26145}{26204}我们先整出来
{26205}{26542}写着 _这样一串_ 的一行
{26556}{26632}那么这是一条登录记录
{26646}{26775}有人打算以 `Disconnected from` 作为用户名登录
{26802}{26841}_（学生）少了个 `s`_
{26842}{26991}少了个 `s` 吗？emmmm...
{26992}{27015}_（学生）第一个 `Disconnected`_
{27016}{27075}**`Disconnected`** 多谢
{27122}{27221}那么你会发现这个命令连用户名一起移除了
{27222}{27297}这是因为像 `.*`
{27301}{27377}这种匹配一个**范围**的表达式
{27383}{27425}它们是用贪心策略
{27426}{27496}去尽可能多的匹配
{27497}{27633}因此虽然我们在这里想保留用户名
{27644}{27794}但是这个 pattern 会一路匹配到它第二次
{27795}{27835}也就是最后一次出现
{27836}{27900}所以包括用户名在内
{27901}{27960}在这之前出现的文本都会被删掉
{27966}{28003}那么我们就要想一个
{28004}{28053}机智一点的方法来匹配
{28054}{28109}而不仅仅是使用 `.*`
{28119}{28193}这样如果输入比较诡异
{28194}{28253}可能会输出一些诡异的东西
{28279}{28385}好 让我们来看看怎么匹配这些行
{28394}{28466}首先先跑个 `head` （过滤一下）
{28674}{28756}嗯...让我们从头开始构造这个 pattern
{28801}{28881}显然我们不想 `\` 满地跑
{28882}{28990}因此首先我们整个 `-E`
{29004}{29069}这些行是这样一个形式
{29070}{29129}先是 `from`
{29130}{29203}有些写了 `invalid`
{29231}{29348}有些又没有 是吧
{29357}{29431}那这里的问号就是匹配 0 或 1 次
{29442}{29491}那这样写就是说
{29492}{29565}0 或 1 个 invalid 后面跟个空格\
{29581}{29630}然后是 `user`……？
{29711}{29786}啊——多了个空格 可不敢乱多
{29809}{29892}然后后面有个用户名
{29910}{30008}然后后面是...
{30009}{30093}然后后面是个 IP 地址
{30100}{30188}这里可以用区间匹配的那些语法
{30189}{30269}这个的意思就是 匹配 `0` 到 `9` 或者 `.` 
{30287}{30355}这是 IP 地址的特征
{30371}{30424}而且我们要匹配多次
{30472}{30538}然后后面是 `port`（端口）
{30539}{30598}所以我们匹配一个固定的字符串 `port`
{30599}{30754}然后再来一次数字 `0` 到 `9`，匹配多次
{30827}{30904}除此之外我们还要做一件事
{30905}{30950}我们要给表达式打锚点
{30951}{31034}正则表达式里有两个特殊字符
{31035}{31150}`^` 匹配行开头
{31161}{31227}而 `$` 匹配行结尾
{31255}{31293}那我们这样写
{31294}{31391}就代表着这个正则表达式匹配了一整行
{31420}{31458}为什么要这样写呢
{31459}{31532}假设有个人把它的用户名
{31533}{31596}设成了这一整条日志文本
{31624}{31676}那当你匹配的时候
{31677}{31777}就会匹配到用户名
{31788}{31824}坏耶——
{31842}{31920}一般来说锚点能加尽量加
{31921}{31980}避免这种偶然事件发生
{31992}{32059}现在看看跑这个命令有什么效果
{32064}{32111}这个命令删掉了好多行
{32114}{32146}但还是留下来了一些
{32151}{32249}例如这个 最后有个 `[preauth]`
{32268}{32343}那我们把它炖了吧
{32349}{32486}空格，`preauth`，方括号
{32487}{32545}方括号是特殊字符要转义
{32561}{32577}好耶
{32583}{32669}再多来几行呢
{32691}{32750}啊 还是有奇怪的东西
{32751}{32792}这些行非空
{32793}{32852}那就意味着 pattern 和它不匹配
{32885}{32924}拿这个来说
{32925}{33023}它写的是 `authenticating` 而不是 `invalid`
{33032}{33061}好吧
{33093}{33164}改成 `invalid` 或者 `authenticating` 之一
{33165}{33216}在用户名之前匹配零次或一次
{33248}{33272}现在如何
{33312}{33365}看上去挺稳的
{33386}{33466}但是这个输出没多少用啊
{33467}{33533}它只是成功地
{33534}{33593}把日志的每一行都清空了
{33594}{33642}这不太有用啊
{33650}{33722}相反我们真正想要做的是
{33723}{33802}当我们在这里匹配用户名时
{33809}{33892}我们更想要记录下来用户名是什么
{33893}{33947}因为这是我们想要输出的内容
{33983}{34046}在正则表达式中做这件事的方法
{34056}{34134}是用一个叫「捕获组」的玩意（Capture Groups）
{34161}{34273}「捕获组」用来表示
{34274}{34369}我想要记住这个值
{34377}{34416}并在之后使用
{34423}{34480}在正则表达式中
{34481}{34566}任何圆括号括起来的表达式
{34575}{34624}就是这样一个捕获组
{34629}{34688}所以我们已经在这里用了一个了
{34704}{34794}这是第一组，现在我们在这儿再建第二组
{34810}{34898}注意这些括号并不影响匹配
{34920}{34958}对吧？因为它们仅仅表达了
{34959}{35011}将这个表达式作为一个单元
{35012}{35069}但它的后面没有任何修饰符
{35070}{35111}所以还是只匹配一次
{35156}{35284}然后捕获组有用的原因是
{35289}{35376}你可以在替换式（replacement）中使用它
{35385}{35429}这样，在这里的替换式处
{35430}{35489}我可以键入 `\2` [*]
{35498}{35583}这是你指代捕获组编号的方法
{35590}{35643}这里我写的意思是
{35644}{35683}先匹配整行
{35690}{35866}之后在替换式处放入你在第二个捕获组匹配到的值
{35883}{35936}好的，记住这是第一个捕获组
{35945}{35975}这是第二个
{36023}{36066}现在它给了我所有的用户名
{36083}{36145}现在来看看写出来的表达式
{36146}{36229}它还挺复杂的，对吧
{36235}{36275}当我们一步步地完善它之后
{36276}{36304}你现在可能会明白
{36306}{36353}为什么它必须是它现在这个样子
{36354}{36406}但要搞懂代码执行起来如何
{36407}{36458}其实并不是很直观的事情
{36464}{36619}这就是正则表达式调试器的用武之地了
{36641}{36673}我们这里有一个
{36681}{36795}网上有很多，这个我已经提前填好了
{36796}{36852}我们刚刚用过的表达式
{36853}{36990}注意到，它上面显示了所有的匹配结果
{37007}{37147}这个窗口配这个字体，字太小了
{37162}{37310}但是如果我……这里，这个注释说
{37311}{37450}`.*` 匹配所有字符 0 次到任意次
{37470}{37580}后面是 `Disconnected from` 这几个词
{37589}{37625}后面是一个捕获组
{37626}{37685}下面还有各种别的
{37692}{37741}这是一个功能
{37742}{37803}它还允许你指定测试字符串
{37804}{37929}之后对给定的每个测试串跑正则表达式
{37933}{38030}并且像这样给不同的捕获组着色
{38051}{38158}这里，我们将用户作为一个捕获组，对吧
{38213}{38265}它显示整个串都匹配到了
{38266}{38325}整个串是蓝色的所以匹配完成
{38337}{38389}绿色部分是第一个捕获组
{38395}{38440}红色是第二个捕获组
{38445}{38477}这是第三个
{38487}{38555}因为 preauth 也被括号括起来了
{38577}{38669}这会是一个调试正则表达式的好方法
{38670}{38777}例如如果我放 Disconnected from……
{38822}{38901}我们这里新添一行
{38993}{39070}如果我把 Disconnected from 作为用户名
{39131}{39216}好吧现在这行已经有这个用户名了
{39231}{39276}我这是未卜先知
{39293}{39346}你会注意到利用这种匹配模式
{39378}{39462}这不再是一个问题
{39465}{39513}因为它正确地匹配了用户名
{39521}{39773}如果我们把这整行或这行变成用户名会发生什么
{39801}{39843}如你所见
{39919}{39955}真让人摸不着头脑
{40008}{40092}将正则表达式调对会很痛苦
{40111}{40175}它现在尝试匹配……
{40200}{40257}它匹配到的第一个组
{40258}{40361}也就是用户名，似乎是第一个 invalid
{40394}{40429}啊，第二个 invalid
{40430}{40462}因为它是贪心的
{40475}{40517}通过在这里加一个 `?`
{40527}{40569}我可以将它变为非贪心的
{40589}{40721}所以如果你在 `+` 或者 `*` 后加 `?`
{40730}{40790}它会变成非贪心匹配
{40791}{40856}也就是不会尽可能地向后匹配
{40865}{40923}这样你可以看到，这个串被正确地解析了
{40935}{41049}因为 `.*` 匹配会在第一个 Disconnected from 处停止 [*]
{41055}{41143}也就是 SSH 指令固定输出的那个
{41153}{41207}是实际出现在我们记录中的那一个
{41297}{41374}讲到现在，你大概也发现了
{41375}{41452}正则表达式会非常复杂
{41459}{41530}你也很可能会在你写的匹配模式中
{41531}{41589}用到各种各样迷惑的修饰符
{41598}{41651}真正学会它的唯一方式
{41652}{41699}是从简单的表达式开始
{41700}{41721}之后堆砌起来
{41722}{41755}直到它匹配到你想要的
{41767}{41851}通常你仅仅是在做一些一次性工作
{41852}{41897}比如刚才我要提取用户名
{41898}{41988}你不需要去考虑那么多特殊情况，对吧
{41992}{42095}你不需要考虑某人的 SSH 的用户名
{42096}{42149}完美地匹配了登录记录的格式
{42165}{42214}这也不算什么大事
{42215}{42269}因为你只是找用户名而已
{42283}{42326}正则表达式确实很强大
{42327}{42422}处理的内容很重要的时候，记得万分小心
{42435}{42455}你要提问吗？
{42635}{42764}总之正则表达式默认只逐行匹配
{42799}{42878}它不会跨行匹配
{43124}{43199}所以 sed 运行的方式是
{43200}{43255}它逐行处理
{43269}{43399}所以 sed 会对每一行匹配这个表达式
{43493}{43583}好，正则表达式或者模式相关问题到此为止
{43584}{43622}它是一个复杂的模式
{43623}{43709}所以如果感到迷惑，别担心
{43710}{43769}课上完了，回去在调试器中看一看
{44103}{44170}所以记住
{44171}{44204}我们在这里假设
{44205}{44306}用户只能控制他们的用户名，对吗？
{44337}{44377}所以他们能做的最坏的事
{44378}{44468}就是把这种整条记录设为用户名
{44469}{44528}我们看会发生什么
{44627}{44665}好的，这是运行结果
{44666}{44788}它的原因是，`?` 意味着
{44789}{44848}我们一遇到 Disconnected (from) 这个词
{44857}{44908}就立刻匹配后面的模式，对吧
{44950}{45065}第一个 Disconnected 是 SSH 自己输出的
{45066}{45125}一定在用户可编辑的内容之前
{45137}{45181}所以在这个特例下
{45182}{45252}即使这样也不会干扰模式串
{45258}{45274}你要提问吗？
{45297}{45446}_（学生有关模式串的数据安全性的问题）_
{45483}{45611}啊，如果你在写一个……
{45612}{45701}这种比较怪的的匹配模式……
{45708}{45782}总的来说，你在做数据整理的时候
{45783}{45885}一般它不会涉及（信息）安全
{45890}{45969}但你很可能会得到很怪异的数据
{45984}{46036}所以如果你在做一些像
{46037}{46064}绘制图表之类的事
{46065}{46109}你可能会丢掉重要的数据点
{46110}{46169}你可能解析出错误的数值
{46170}{46288}之后你的表突然出现了原始数据中没有的数据点
{46289}{46321}所以重要的是
{46322}{46417}如果你发现你在写一个复杂的正则
{46418}{46459}多检查几下
{46460}{46513}它匹配出来的是不是你想要的
{46514}{46589}即使它与信息安全无关
{46677}{46705}和你想的一样
{46706}{46779}这些模式串可能会非常复杂
{46780}{46855}例如这里有一个讨论
{46856}{46945}关于如何用正则表达式匹配一个 email 地址
{46956}{46999}你可能会想到像这样的
{47001}{47082}这是一个非常直观的表达式
{47083}{47237}只是字母，数字，一些字符，后面一个 `+`
{47238}{47343}因为在 Gmail 里，email 地址里可以有 `+` [*]
{47367}{47530}这里的 `+` 只表示任何这些字符至少出现一个
{47537}{47609}因为你不会有一个 @ 前为空的 email 地址
{47618}{47683}后面域名的规则也差不多，对吧
{47696}{47809}顶级域需要至少两个字符并且不能包括数字
{47816}{47895}你可以是 .com 但是不能是 .7
{47928}{47996}事实上这并不完全正确
{47997}{48097}这里有一堆有效的 email 地址不会被它匹配
{48098}{48175}还有一堆无效的 email 地址会被它匹配
{48188}{48316}所以有很多很多建议
{48317}{48398}还有热心网友写了的完整的测试套件
{48399}{48476}尝试判断哪一个正则表达式是最好的
{48531}{48609}这是一个专门给 URL 的
{48610}{48670}这是类似的给 email 的
{48671}{48731}他们发现最好的就是这个
{48776}{48851}我不建议你去试着理解这个模式串 [*]
{48857}{48982}但这个很明显会几乎完美的匹配到
{48983}{49086}像符合互联网标准的 email 地址
{49087}{49125}就是所说的有效 email 地址
{49132}{49224}它还包含 Unicode 里奇奇怪怪的编码
{49231}{49321}这只是想说明正则表达式可以非常长
{49328}{49373}如果最后你写出像这样的表达式
{49374}{49433}很可能会有更好的方式去做
{49461}{49576}比如，如果你自己在试着解析 HTML 
{49577}{49751}或者解析 JSON 格式，对于这种格式来说
{49752}{49793}去用其它工具大概会比较好
{49802}{49879}我们也有这样的练习
{49883}{49940}不是用正则表达式，提醒你
{50039}{50142}这里有各种各样的建议
{50143}{50233}还非常非常深入地展示了它的运行过程
{50234}{50314}如果你想查阅，它在课程笔记里
{50408}{50479}好的，我们有了这些用户名
{50502}{50545}让我们回到数据整理
{50546}{50597}像这列用户名
{50607}{50671}它仍然对我很不友好，对吗？
{50672}{50717}让我们看看总共有几行
{50718}{50782}如果我键入 `wc -l`
{50798}{50831}这有……
{50903}{50965}一十九万八千行
{50974}{51043}这个 `wc` 是计数程序（**w**ord **c**ount）
{51044}{51100}`-l` 选项是统计行数
{51112}{51164}所以这么多行
{51165}{51266}如果我只是边翻边看，意义也不大
{51270}{51329}对吧，我需要的是统计数据
{51330}{51382}我需要找个方法合计数据
{51476}{51541}虽然 `sed` 这个工具用途很广
{51542}{51587}它支持一个完整的编程语言
{51588}{51673}可以做一些，比如插入文本
{51674}{51739}或者只输出匹配行的操作
{51740}{51831}但它不是应付一切的完美工具，明白吗
{51832}{51884}有时候有更好的选择
{51885}{51944}就比如说，你可以用 `sed` 
{51945}{51995}编程实现行数统计
{51996}{52039}但绝对别这么干
{52040}{52096}除了搜索替换之外
{52097}{52144}`sed` 的语法挺烂的
{52194}{52251}但是，还有别的好用的工具
{52252}{52347}比如有个叫 `sort` 的
{52427}{52486}虽然它泛用性不高
{52487}{52565}`sort` 会接受很多行的输入
{52573}{52632}排一个序，然后输出到输出流
{52649}{52759}现在，我有了这个排序后的列表
{52760}{52853}它仍然有二十万行，所以还不是很好
{52868}{52974}但现在我可以把 `uniq` 结合进来
{52985}{53011}这个工具 `uniq` 
{53012}{53089}作用在多行有序的输入上
{53099}{53182}输出去重后的输入
{53189}{53277}也即，如果你有重复的行
{53282}{53321}这些行只会被打印一次
{53336}{53408}我可以执行 `uniq -c`
{53417}{53580}意为，对重复的行，计算它们重复的数量
{53581}{53612}然后将其（从输出中）去除
{53628}{53654}这会输出什么呢？
{53662}{53771}呃，如果我执行它，会处理一会
{53780}{53878}里边有 13 个 `zzz` 用户名
{53879}{53973}10 个 `zxvf` 用户名，等等
{53978}{54022}我可以上下翻看
{54023}{54083}这仍是一个很长的表单，对吧
{54084}{54202}但现在，至少比原来稍微条理点了
{54209}{54281}看看现在我们提出来多少行
{54393}{54480}好，两万四千行，仍然很多
{54481}{54530}虽然对我而言，这些信息没用
{54539}{54624}但我可以用更多工具，不断缩减它
{54638}{54703}比如我可能想知道
{54704}{54769}哪个用户名出现的最多
{54789}{54845}我可以再排个序
{54856}{54996}我想要对输入的第一列做数值排序
{55019}{55098}所以 `-n` 意为数值排序
{55099}{55154}`-k` 允许你在输入中
{55155}{55263}选中空白字符分隔的一列，执行排序
{55269}{55351}这里我加了一个 `,1` 的原因是
{55352}{55457}我想要计数第一列到第一列
{55472}{55501}除此之外我也可以要求
{55502}{55586}依据所有的列排序 [*]
{55598}{55663}但这里我只想用第一列
{55720}{55820}然后我只想要最后十列
{55821}{55961}`sort` 默认是以升序输出
{56011}{56093}所以计数最高的一条在最底下
{56094}{56158}然后我就只要最后十列
{56223}{56262}现在再跑的时候
{56270}{56344}我就有比较有用的数据了，对吧
{56345}{56476}它告诉我用户名 `root` 有一万多次登录尝试
{56481}{56633}用户名 `123456` 有四千多次
{56661}{56714}这就很棒了
{56738}{56907}现在这个大日志突然就给我有用信息了
{56912}{56986}这是我真正想从日志里要的信息
{56994}{57046}现在我可能就想，比如
{57047}{57129}快速地禁用一下我机器上
{57130}{57200}比如 SSH 登录的 `root` 用户名
{57223}{57271}顺便我也建议你们这样做
{57364}{57400}其实对于这个情况
{57401}{57460}我们不需要 `sort` 的 `-k`
{57474}{57567}因为 `sort` 默认按（从前到后的）列排序
{57568}{57619}而数字又恰巧是最前面一列
{57625}{57685}但了解这些额外的 flag 是有益的
{57708}{57794}你可能想问，我是怎么知道有这些 flag 的
{57795}{57854}我是怎么了解这些程序的存在的
{57873}{57945}嗯，通常这些程序是
{57946}{58009}在这种课堂上知道的
{58018}{58074}至于这些 flag
{58097}{58154}经常是，我想按照某个基准排序
{58155}{58205}但不是按整行
{58226}{58304}那你的第一反应是键入 `man sort`
{58305}{58343}然后把页面读一遍
{58359}{58407}你很快就能知道怎么能
{58408}{58457}优雅地选中一行
{58458}{58517}怎么能像这样，选这行数字
{58604}{58699}好，如果，我们现在有了这个……
{58700}{58749}就让它是前 20 的表单
{58779}{58836}假设我并不关心具体数量
{58845}{58938}我只要一个逗号分隔开的用户名表单
{58949}{58989}因为我可能打算通过电邮
{58990}{59065}每天都把它发给自己，之类的
{59066}{59170}像是《震惊！今天攻击者最喜欢的二十个用户名竟是...》
{59188}{59278}嗯，我可以这样——
{59372}{59431}好，出现了更多怪怪的命令
{59432}{59488}但了解它们都是有意义的
{59499}{59643}这个 `awk` 是基于列的流编辑器
{59656}{59734}我们提到了流编辑器 `sed`
{59741}{59835}它主要是编辑输入进来的文本 
{59843}{59960}此外，`awk` 也让你编辑文本
{59961}{60012}也是一个完整的编程语言
{60017}{60083}但它专注于基于「列」的数据
{60093}{60151}所以这里 `awk` 会以默认方式
{60152}{60262}解析空格分隔的输入
{60272}{60343}然后你可以分别处理这些行
{60350}{60415}我这里告诉它只打印第二行
{60422}{60476}就是用户名那行，对吧
{60531}{60568}`paste` 这个程序
{60572}{60659}能借助 `-s` 选项，将一大堆行的输入
{60662}{60725}处理成以 tab 分隔的一行
{60732}{60782}这里 `-d` 使其以 `,` 分隔，而不是 tab
{60819}{60895}这里，这个例子，我想要一个
{60896}{60970}逗号分隔的最靠前的用户名列表
{60989}{61057}然后我就可以物尽其用
{61068}{61132}比如我把它丢进一个配置文件
{61133}{61192}去禁止这些用户名啥的
{61258}{61341}`awk` 值得我多费几句口舌
{61342}{61430}讲白了，对于这样的数据整理
{61431}{61490}它是一个非常有力的语言
{61542}{61657}我简单说了这个 `print $2` 做什么
{61682}{61820}但你可以用 `awk` 施展一些绚丽的魔法
{61821}{61922}比如，我们先回到处理用户名这里
{61932}{62053}然后……我们还是执行 `sort` 和 `uniq` 吧
{62112}{62161}不然这个表单就太长了
{62172}{62254}然后让我们只输出那些
{62260}{62320}和特定模式相符的用户名
{62365}{62459}比如，让我想想……
{62591}{62643}`uniq -c`
{62666}{62834}我要只出现一次，并且
{62852}{62953}以 c 开头、e 结尾的所有用户名
{62985}{63040}虽然我们在搜索一个奇怪的东西
{63051}{63128}但在 `awk` 里面写出来还挺容易
{63134}{63200}我可以让第一列是 `1` 
{63236}{63403}并且第二列匹配这个正则
{63628}{63687}*好像这里只用 `.` 就行*
{63797}{63858}然后我想按整行打印
{63959}{63995}除非我搞错了什么东西
{64008}{64142}不然这就是所有以 c 开头，e 结尾
{64143}{64202}并且只出现了一次的用户名
{64256}{64352}虽然对数据做这种处理没有意义
{64358}{64417}但我在课上想讲的是
{64418}{64466}各种可以运用的工具
{64475}{64566}并且虽然我们举的例子很奇怪
{64567}{64626}但这个 pattern 并不复杂
{64636}{64753}这是因为某些 Linux 的工具
{64754}{64802}以及普遍的命令行工具
{64820}{64942}都是按照以行为单位的输入输出而设计
{64947}{65054}并且这些行经常会分为多列
{65055}{65127}而 `awk` 就是处理列的能手
{65339}{65509}`awk` 不仅能做这种匹配每行的操作
{65546}{65628}而且，比如说……
{65629}{65688}让我先输出一下行数
{65689}{65768}我想知道多少用户名符合这个模式
{65778}{65855}我可以执行 `wc -l`，这样就挺好
{65901}{65965}有 31 个这样的用户名
{65974}{66025}但 `awk` 是编程语言啊
{66040}{66178}这个黑魔法，你估计不会想去碰它
{66186}{66236}但要知道你可以运用
{66237}{66348}知道这些，对现在和以后都有益
{66426}{66516}在我屏幕上可能不太好读懂
{66518}{66554}我也发现了……
{66647}{66701}我马上处理一下
{66647}{66727}稍等，让我试着修一下这个锅
{66834}{66935}运行这个试试，啊！
{67008}{67058}显然，fish 不想让我这么做
{67061}{67240}看， `BEGIN` 在第一行的开头被匹配到
{67242}{67389}`END` 在最后一行的末尾被匹配到
{67405}{67514}然后这些是普通的逐行匹配正则
{67516}{67552}所以，我写的这些意思是
{67554}{67651}在第零行开始， `rows` 这个变量被赋值为 0
{67652}{67723}对于能匹配这个规则的文本行
{67724}{67774}`rows` 的值就会增加
{67775}{67859}当你匹配完最后一行的时候
{67860}{67918}就把 `rows` 这个变量的值打印出来
{67932}{68014}这和运行 `wc -l` 差不多
{68016}{68059}但是这些都是用 awk 运行的
{68061}{68161}通常 `wc -l` 就有不错的效果
{68163}{68243}但是如果你想做些别的
{68244}{68343}比如维护一个字典或者 map [*]
{68345}{68399}或者统计一些数据
{68400}{68520}再或者是…我想找第二个符合匹配的结果
{68521}{68576}所以你需要一个有状态的匹配器
{68577}{68623}比方说忽略匹配到的第一个结果
{68624}{68689}从第二个符合条件的结果开始逐个输出
{68690}{68800}这样的话，懂几行 awk 就很有用了
{68897}{68966}实际上，在现在这种情况下
{68967}{69013}我们可以撇掉之前处理文件使用的
{69014}{69167}`sed sort uniq` 和 `grep` 这些命令
{69168}{69209}然后用 awk 取而代之
{69210}{69259}但你大概不愿意这样做
{69260}{69353}这样做不值得，反倒可能让你很痛苦
{69406}{69515}再来说一说命令行里
{69518}{69587}别的非常好用的工具
{69588}{69689}首先是一个很方便的程序，叫做 bc
{69690}{69776}或许 bc 是 **B**erkeley **C**alculator?
{69777}{69802}我想应该是吧
{69803}{69841}`man bc`
{69880}{69956}我想 bc 应该是起源于 Berkeley calculator 吧？
{69966}{70051}无所谓了，它是一个简洁的命令行计算器
{70052}{70115}它并没有给你个提示符，让你输入
{70116}{70165}而是直接从标准输入读数据
{70166}{70304}所以我能这样 `echo "1 + 2" | bc -l` 
{70305}{70369}（要加 `-l`）因为好多这样的程序
{70370}{70479}默认的运行模式都很不智能
{70536}{70610}好，它输出了 3
{70611}{70654}哇，太强了
{70670}{70731}同时这也说明它用起来挺方便的
{70732}{70823}想象一下，你有一个有很多行的文件
{70824}{70956}比如说，唔，不知道整啥好了
{70991}{71052}比方说，在这个文件里
{71053}{71230}我想把登录的次数加起来
{71231}{71318}把出现不止一次的名字个数加起来
{71319}{71461}这里写，第一个匹配组的内容不为 1
{71474}{71558}然后只把这个次数输出
{71612}{71665}程序就会告诉我
{71666}{71755}所有登录了不止一次的用户都登录了几次
{71756}{71837}然后我还想了解一下总数是多少
{71838}{71887}注意我不能只数一下有多少行
{71888}{71924}这样是有问题的，对吧
{71925}{72028}因为每一行都有对应的次数，我得把他们都加起来
{72029}{72088}那么，我可以用 `paste` 命令
{72089}{72157}一边粘贴输入，一边附上加号
{72158}{72288}这样就把所有行用 `+` 连接成了一行加法式
{72317}{72388}这就是一个算术表达式
{72389}{72468}这样就可以把它 pipe 到 `bc -l` 
{72469}{72610}可以看到，总共有十九万一千多个用户名
{72611}{72703}登录了不止一次
{72704}{72796}你可能并不关心这个结果
{72797}{72926}这只是展示一下你可以轻松提取这些数据
{72994}{73073}你还可以用这些数据做很多别的事
{73074}{73187}有用来计算和统计输入数据的工具
{73206}{73301}比如说，对于刚刚这列数字
{73302}{73393}这样，我们重新只输出数字
{73419}{73481}按顺序输出数字
{73508}{73636}然后我可以用 R 跑一下
{73637}{73683}R 是一门独立的编程语言
{73684}{73761}针对数据的统计分析而设计
{73783}{73833}我可以这样写
{73852}{73915}看看我能不能搞对
{73935}{74093}它也是一个新的编程语言，你要专门去学
{74141}{74250}先假设你会用 R，但也可以 pipe 给别的语言
{74475}{74616}这样我就得到了一个输入数字的统计结果
{74642}{74768}所以各用户名登录次数的中位数是 3
{74784}{74863}最大值是一万多，我们之前看过了，这个是 root 产生的
{74864}{74912}还告诉我平均值是 8
{74947}{75004}这些在目前的这个例子里可能没有意义
{75005}{75053}这些不是什么有意义的数据
{75054}{75148}但是，处理比如统计脚本的输出，或者别的一些
{75157}{75234}会有明显数值分布的数据时
{75235}{75326}如果你想看这种数据，这些工具就有用了
{75381}{75455}我们甚至可以画个简单的图表
{75506}{75556}这里是一堆数字
{75565}{75713}我们回到前面，`sort -nk1,1`
{75723}{75823}然后只保留，就最前面五个吧
{75862}{75934}`gnuplot` 是一个画图表的工具
{75947}{76017}可以接受标准输入
{76126}{76214}我不期望你们都会这些编程语言
{76263}{76345}毕竟他们都是实打实的一门门编程语言
{76356}{76414}只是展示一下你的工具选择
{76502}{76565}现在这就有了一个大直方图
{76566}{76661}是前五个用户，自从 1 月 1 日开始
{76662}{76768}都各被用了多少次的图表
{76818}{76870}这只用了一行命令
{76896}{77011}虽然它特别长特别复杂，但只用一行就可以
{77144}{77224}这节课的最后我再说两句
{77225}{77321}还有两种特别的数据处理
{77334}{77450}首先是命令行参数的处理
{77475}{77646}有时候你会遇到一些情况……
{77647}{77747}比如上节课讲过的 `find` 命令
{77748}{77816}会产生一连串的文件名
{77817}{77927}或者一些命令可能产生一连串的……
{77995}{78064}参数，传给你的评测脚本
{78065}{78150}比如你想带上有特定数值分布的参数运行
{78151}{78181}比如你有一个脚本
{78182}{78287}会给一个程序提供它迭代次数的数值
{78288}{78359}然后你想让这组数值呈指数分布之类的
{78360}{78440}然后这个脚本会逐行输出每个迭代次数
{78441}{78527}你想要照此依次运行程序
{78528}{78608}正好，这有个叫 `xargs` 的工具是你的好帮手
{78614}{78800}`xargs` 接受若干行输出，把它们转为参数形式
{78816}{78950}这可能有点怪，我看看有啥好例子吗
{78951}{79014}这样，我会用 Rust 编程[*]
{79015}{79132}Rust 允许你安装前后多个版本的编译器
{79133}{79225}在这里你可以看到稳定版、Beta 版
{79226}{79328}还有几个早期的稳定发布版
{79329}{79390}还有一堆过期了的 nightly 版本
{79400}{79447}这功能还挺不错的
{79448}{79486}但是很长时间过去之后
{79487}{79580}就不需要留着这些 nightly 版本了
{79581}{79650}像这种去年三月份的
{79651}{79682}我可以删掉这些
{79683}{79753}我从今往后可能还想清理一下
{79776}{79855}这是一个多行的列表
{79862}{79904}我可以先找出 nightly
{79940}{80033}我可以去掉……`-V` 是不要匹配
{80080}{80148}我不想匹配最新的 nightly
{80159}{80251}好，这是一些有年头的 nightly
{79647}{79681}那我大概就可以把它们删了
{79682}{79741}那我现在想把这个列表整干净些
{79805}{79849}这是一个多行的列表
{79862}{79897}那我先 `grep nightly`
{79914}{79968}然后我把最新版的 `nightly` 排除掉
{79969}{80028}用 `-v` 来表示不匹配它
{80078}{80135}我不想要匹配当前的`nightly`版本
{80157}{80240}好现在这些 `nightly` 都带着日期
{80250}{80307}我只想留下 2019 年的 [*]
{80379}{80464}那现在我想把这一个个工具链
{80465}{80528}从我的电脑里删掉
{80544}{80597}我固然可以一行行的来回复制粘贴
{80623}{80729}`rustup toolchain remove`
{80748}{80851}哦，好像是 `uninstall`
{80866}{80944}那我可以手动的输入这些文件名
{80945}{80970}也可以复制粘贴
{80971}{81025}但是这不是很烦么
{81026}{81067}我都整出来列表了啊
{81081}{81106}那要不这样吧
{81107}{81361}我用 `sed` 把这些版本号的后缀去掉
{81422}{81461}好，就这个样子
{81474}{81521}然后用 `xargs` 
{81522}{81671}它可以把输入的列表转成参数
{81686}{81847}这里我想让它变成这个命令的参数
{81891}{81971}我的习惯是这里加个 `echo`
{81972}{82031}这样就可以看到它将会干些什么 [*]
{82053}{82097}啊这输出没太大用
{82107}{82168}并不是很好读
{82175}{82239}仔细看这个命令
{82247}{82282}删掉 `echo` 之后
{82285}{82342}将会执行 `rustup toolchain uninstall`
{82343}{82380}然后后面是 `nightly` 版本
{82381}{82431}作为**参数**传给程序
{82452}{82487}那我一跑这个命令
{82514}{82556}它就会把这些工具链删了
{82557}{82606}那我就不用一个个复制粘贴了
{82668}{82729}那这就是数据处理
{82730}{82777}在辅助其他工作上的应用
{82778}{82831}在观察数据之外更进一步
{82832}{82858}也就是把一种形式的数据
{82859}{82878}转换成了另一种
{82898}{82959}你还可以处理二进制数据
{82974}{83017}而图像、视频等
{83018}{83077}就是一个很好的例子
{83078}{83221}你可以拿它们来整点有趣的活
{83226}{83283}例如有个工具叫 `ffmpeg`
{83289}{83374}它是用来编解码视频的工具
{83375}{83425}也可以整点图像活
{83448}{83487}我现在把它的日志级别
{83490}{83514}设成 `panic` 
{83516}{83557}不然它会输出超多东西
{83583}{83666}我想让它从 `/dev/video0`
{83677}{83768}也就是从我的摄像头读取
{83814}{83902}然后把第一帧拿出来
{83903}{83939}也就是拍个照
{83976}{84035}然后输出成一张图
{84036}{84103}而不是一个单帧的视频
{84136}{84238}我想让它把输出内容，也就是这个图片
{84239}{84265}输出到 `stdout`
{84272}{84338}一般用 `-` 就告诉程序
{84339}{84389}从标准流来输入输出
{84390}{84423}而不要用文件
{84431}{84472}这个参数应该是给出一个文件名
{84473}{84548}而用 `-` 作为文件名就代表 `stdout`
{84554}{84639}然后我想把它用管道
{84644}{84687}接到 `convert` 这个程序
{84699}{84779}`convert` 是一个图像处理软件
{84789}{84873}我想让 `convert` 从 `stdin` 读入
{84912}{85027}然后把图片转成灰度的
{85028}{85172}然后把结果写到 `-` 文件里
{85173}{85204}也就是标准输出
{85244}{85319}然后我想接给 `gzip` 
{85328}{85388}它可以压缩这个图片文件
{85433}{85529}它也会用标准流来输入输出
{85554}{85620}然后我会把它接到
{85621}{85675}我的远程服务器上
{85705}{85793}在那上面解码（解压缩）
{85830}{85902}然后把图像存个副本
{85920}{85953}复习一下
{85954}{85985}`tee` 会从 `stdin` 输入
{85986}{86024}然后输出到文件和 `stdout`
{86025}{86057}那这样我们就得到了一份
{86064}{86146}名字是 `copy.png` 的
{86160}{86201}解码过的图像副本
{86256}{86323}继续沿着管道推流
{86335}{86437}我再把数据流导向本地
{86466}{86605}我想让它在一个图片查看器里显示出来
{86606}{86639}看看能不能用
{86676}{86699}瓦！
{86736}{86841}好 这张图经过我的服务器
{86853}{86935}然后又由管道传回来了
{86952}{87064}此外我的服务器理论上
{87065}{87163}有这张图解码后的副本
{87164}{87194}来看看有没有
{87203}{87299}`scp copy.png` 到我这里
{87320}{87342}啊这
{87343}{87382}这样呢
{87507}{87611}看！完全一致！这个命令生效了
{87648}{87711}这是个简单的例子
{87712}{87812}但是你会见识到这样构建管道的强大之处
{87813}{87874}它不一定要是文本
{87875}{87931}而是会把任意格式的数据
{87932}{87950}转换成另一种格式
{87962}{88022}如果想要的话
{88023}{88081}我可以 `cat /dev/video0`
{88082}{88135}然后把它用管道接到
{88136}{88206}Anish 的服务器上
{88207}{88307}他就可以把它 `pipe` 到视频播放器上
{88308}{88400}然后在他的机器上看视频了
{88443}{88498}只要知道有这么个操作就好
{88575}{88646}今天有许多的练习可以做
{88647}{88720}有些呢会用到一些数据源
{88721}{88820}像是 macOS 和 Linux 的日志
{88821}{88844}然后我们会告诉你用哪些命令
{88845}{88877}你可以自己玩一下
{88886}{88923}但是记住
{88924}{89018}用什么数据源并不重要
{89019}{89083}更重要的是找些
{89084}{89147}你觉得有意思的数据源
{89148}{89214}然后从里面找出有意思的东西
{89215}{89274}这些练习的重点在这里
{89306}{89407}星期一马丁路德金日不上课
{89408}{89480}下一节课周二
{89481}{89519}我们讲命令行环境
{89531}{89593}现在讲的这些有些什么疑问吗
{89594}{89651}管道啊 正则啊 
{89706}{89815}正则这东西真的值得好好看看
{89816}{89868}它太好用了
{89869}{89930}在编程方面也很好用
{89945}{89980}如果有问题
{89981}{90001}~~办公室找我~~
{90002}{90061}我会帮你的
